{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dynamic Programming and Structural Econometrics #5\n",
    "\n",
    "### Function approximation and interpolation\n",
    "\n",
    "**Readings:** \n",
    "- üìñ Judd, K. L. (1998). Numerical methods in economics. MIT press. Section 6\n",
    "- üìñ Jerome Adda and Russell Cooper ‚ÄúDynamic Economics. Quantitative Methods and Applications.‚Äù Sections 3.5 \n",
    "\n",
    "by Bertel Schjerning\n",
    "\n",
    "University of Copenhagen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "- The approximation problem\n",
    "    - How to approximate function f(x) given data of $ f(x) $ in $ n $ points\n",
    "  $ (x_1,\\dots,x_n) $  \n",
    "- Sieve approximation (we can use simple linear regression)\n",
    "    - Examples: Polynomials, Splines\n",
    "    - Properties of approximation methods crucially depends on support of basis functions \n",
    "    - Splines has bounded support $\\rightarrow$ local approximation\n",
    "    - Polynomials has unbounded support $\\rightarrow$ global approximation    \n",
    "- Orthogonal polynomials\n",
    "    - Leading example: Chebyshev polynomials\n",
    "    - Optimal nodes: Chebyshev zeros $\\rightarrow$ minimizes the maximum error bound (min-max property)\n",
    "    - Very good to approximate smooth functions, but has issues with kinks. \n",
    "    \n",
    "- Multivariate extensions\n",
    "    - 1d sieve methods can be directly generalized to d dimensions using a tensor-product basis and a Cartesian grid\n",
    "    - CURSE of Dimensionality\n",
    "    - Solutions: Sparse grids or machine learning (Lasso, Neural nets, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approximation problem\n",
    "\n",
    "- $ f(x) $ is function of interest, hard to compute  \n",
    "- Have data on values of $ f(x) $ in $ n $ points\n",
    "  $ (x_1,\\dots,x_n) $  \n",
    "\n",
    "\n",
    "$$\n",
    "f(x_1), f(x_2), \\dots f(x_n)\n",
    "$$\n",
    "\n",
    "- Need to find the approximate value $\\hat{f}(x)$ of the function $ f(x) $ in\n",
    "  arbitrary points $ x \\in [a,b]$ \n",
    "- We need to extrapolate if $a<x_1$ or $b>x_n$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Before we move on we need some standard libraries, tools for sieve interpolation, tools for potting etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from lib.sieve import * # sieve library for function approximation\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate # Interpolation routines\n",
    "from numpy.polynomial import polynomial\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "- Let's consider the function $f(x)=\\exp(-x/4)\\sin(x) + 1/(1+x^2)$\n",
    "- Assume we have data of values of $f(x)$ in $m$ grid points $x^g=(x_1,\\dots,x_m)$ and want to approximate $f(x)$ for any $x$ on the interval $x \\in [a, b]$\n",
    "- Easy to approximate $f(x)$ with a simple linear interpolation\n",
    "- Can we find a better approximation $\\hat{f}(x)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m; a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m; b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m;            \u001b[38;5;66;03m# m:   Number of datapoints and limits for on interval  \u001b[39;00m\n\u001b[1;32m      2\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(a,b,m);   \u001b[38;5;66;03m# x0:  grid points where we know f(x)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m fx0\u001b[38;5;241m=\u001b[39m\u001b[43mf\u001b[49m(x0)                  \u001b[38;5;66;03m# fx0: function values at x0\u001b[39;00m\n\u001b[1;32m      4\u001b[0m fhat \u001b[38;5;241m=\u001b[39m interpolate\u001b[38;5;241m.\u001b[39minterp1d(x0,fx0) \u001b[38;5;66;03m# returns the interpolation function\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plot1d(f, x0, fx0, fhat, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear Interpolation\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# use the the plotting tool\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "m=6; a=-2; b=2;            # m:   Number of datapoints and limits for on interval  \n",
    "x0 = np.linspace(a,b,m);   # x0:  grid points where we know f(x)\n",
    "fx0=f(x0)                  # fx0: function values at x0\n",
    "fhat = interpolate.interp1d(x0,fx0) # returns the interpolation function\n",
    "plot1d(f, x0, fx0, fhat, label='Linear Interpolation') # use the the plotting tool\n",
    "p = polynomial.polyfit(x0,fx0,m-1) # returns the interpolation function\n",
    "fhat = lambda x: polynomial.polyval(x,p)\n",
    "plot1d(None, x0, fx0, fhat, label='Polynomial', color='g') # use the the plotting tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sieve approximation\n",
    "- **An example a local piecewise approach** is to approximate $f(x)$ by a stepwise flat function. \n",
    "- This would involve dividing the interval $[a,b]=[x_0,x_{n+1}]$ in to $n+1$ subintervals $ [x_j,x_{j+1}] $, $ j=0,\\dots,n$ and approximate $f(x)$ by\n",
    "    $$f(x) \\approx \\sum_{j=0}^{n} \\alpha_j \\mathbb{1}(x_j\\le x < x_{j+1}) $$\n",
    "\n",
    "- **An example of a more smooth approach** is to approximate $f(x)$ (simple algebraic) polynomial of degree $n$ so that \n",
    "    $$f(x) \\approx p_n(x,\\alpha)=\\alpha_0 + \\alpha_1 x + \\alpha_2 x^2 \\dots + \\alpha_n x^n = \\sum_{j=0}^n \\alpha_j x^j $$\n",
    "    \n",
    "- Both approaches are really a special case of the same class of function, **linear sieves**\n",
    "- Linear sieves are essentially linear functions with  $n+1$ parameters and corresponding basis functions $\\{B_i(x)\\}_{i=0}^{n}$ such that\n",
    " $$f(x) \\approx s(x,\\alpha)= \\sum_{j=0}^{n} \\alpha_j B_j(x) $$\n",
    " where $B_j(x)=\\mathbb{1}(x_j\\le x < x_{j+1}) $ for the step-function and $B_j(x)=x^j$ for a simple algebraic polynomial\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do we approximate $f(x)$ by the sieve $s(x,\\alpha)$\n",
    "\n",
    "Suppose that: \n",
    "- We have access to a \"data set\" $ \\{(x_i,f(x_i)\\}, i=1,\\dots,m$  \n",
    "- We know the functional form of the $n+1$ basis functions $\\{B_i(x)\\}_{i=0}^{n}$. For example $B_j(x)=x^j$ in case of simple polynomials\n",
    "\n",
    "- In the case of a linear sieve we can easily \"estimate\" $\\alpha=\\alpha_0,\\dots,\\alpha_{m-1}$   using linear regression based on a set of $m\\ge n+1$ grid points on x and f(x). \n",
    "\n",
    "$$ \\hat{\\alpha} = \\arg \\min_{\\alpha \\in \\mathbb{R}^n} \\sum_{i=1}^{m} \\left[f(x_i)-\\sum_{j=0}^{n} \\alpha_j B_j(x_i) \\right]^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Can we approximate f(x)?\n",
    "Can we find $\\alpha$? \n",
    "- Yes, if we have $m \\ge n+1$ data points and $x_i$ are distinct such that $B_i(x_i)$ are not co-linear, all $n+1$ elements in the vector of sieve coefficients $\\alpha$ are uniquely identified. \n",
    "- Good old OLS $\\alpha=\\left(B(x)'B(x)\\right)^{-1}B(x)'f(x)$\n",
    "\n",
    "\n",
    "Can we deal with with high order polynomials if x is large? \n",
    "- Yes, change of variable from $x\\in [a,b]$ to $z\\in [-1,1]$. \n",
    "\n",
    "Can we approximate f(x). \n",
    "- Yes, at least in the nodes (perfectly if $m=n+1$). \n",
    "- Before we formally study the theoretical properties, let's just try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distinction for function approximation: interpolation and curve fitting\n",
    "\n",
    "- **Interpolation** refers to the situations when **data** on function values is matched **exactly**  \n",
    "  - The approximation curve passes through the points of the data\n",
    "  - If parameters of approximating function is \"estimated\" parameters are *exactly-identified* \n",
    "- **Curve fitting** refers to the statistical problem when the data has\n",
    "  **noise**, the task is to find an approximation for the central\n",
    "  tendency in the data  \n",
    "  - Linear and non-linear regression models, econometrics  \n",
    "  - The model is *over-identified* (there is more data than needed to\n",
    "    exactly identify the regression function) \n",
    "  - For approximations of functions, there is not really noise in our data. However, when the basis does not span the full functional space that $f(x)$ belongs to we will not be able to match all the points and we use ideas similar curve fitting (often linear regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Does sieve $s(x;\\alpha)$ converge to $f(x)$ when there are more points and/or basis functions?\n",
    "- This depends on the function and the choice of basis functions. Let's first focus on polynomials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "f= lambda x: np.exp(-x/4)*np.sin(x) + 1/(1+x**2)    # function to interpolate/approximate\n",
    "# f = lambda x: (np.log(x*2/3)+0.5*np.log(x*1/3))    # TRY another function to approximate (only for x>0)\n",
    "a=0.01; b=5; n=10; deg=9;\n",
    "sa=sieve(n, deg, a, b, btype='algpol', gridtype='u');    sa.plot1d(f); plt.show() # basis: (ordinary) Algrbraic polynomials\n",
    "sc=sieve(n, deg, a, b, btype='chebyshev', gridtype='c'); sc.plot1d(f); plt.show() # basis: Chebyshev polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Least squares approximation\n",
    "\n",
    "We could also go back to **function approximation** and fit polynomials\n",
    "of lower degree\n",
    "\n",
    "- Data set $ \\{(x_i,f(x_i)\\}, i=1,\\dots,m $  \n",
    "- **Any** functional form $ g(x) $ from class $ G $ that best\n",
    "  approximates $ f(x) $  \n",
    "\n",
    "\n",
    "$$\n",
    "g = \\arg\\min_{g \\in G} \\lVert f-g \\rVert ^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Orthogonal polynomial approximation/interpolation\n",
    "\n",
    "- Polynomials over domain $ D $  \n",
    "- Weighting function $ w(x)>0 $  \n",
    "\n",
    "\n",
    "Inner product\n",
    "\n",
    "$$\n",
    "\\langle f,g \\rangle = \\int_D f(x)g(x)w(x)dx\n",
    "$$\n",
    "\n",
    "$ \\{\\phi_i\\} $ is a family of orthogonal polynomials w.r.t.\n",
    "$ w(x) $ iff\n",
    "\n",
    "$$\n",
    "\\langle \\phi_i,\\phi_j \\rangle = 0, i\\ne j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Best polynomial approximation in L2-norm\n",
    "\n",
    "Let $ \\mathcal{P}_n $ denote the space of all polynomials of degree $ n $ over $ D $\n",
    "\n",
    "$$\n",
    "\\lVert f - p \\rVert_2 = \\inf_{q \\in \\mathcal{P}_n} \\lVert f - q \\rVert_2\n",
    "= \\inf_{q \\in \\mathcal{P}_n}  \\left[ \\int_D ( f(x)-q(x) )^2 dx  \\right]^{\\tfrac{1}{2}}\n",
    "$$\n",
    "\n",
    "if and only if\n",
    "\n",
    "$$\n",
    "\\langle f-p,q \\rangle = 0, \\text{ for all } q \\in \\mathcal{P}_n\n",
    "$$\n",
    "\n",
    "*Orthogonal projection is the best approximating polynomial in L2-norm*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Uniform (infinity, sup-) norm\n",
    "\n",
    "$$\n",
    "\\lVert f(x) - g(x) \\rVert_{\\infty} = \\sup_{x \\in D} | f(x) - g(x) |\n",
    "= \\lim_{n \\rightarrow \\infty} \\left[ \\int_D ( f(x)-g(x) )^n dx  \\right]^{\\tfrac{1}{n}}\n",
    "$$\n",
    "\n",
    "Measures the maximum absolute difference over the whole domain $ D $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Chebyshev (minmax) approximation\n",
    "\n",
    "What is the best polynomial approximation in the uniform (infinity, sup) norm?\n",
    "\n",
    "$$\n",
    "\\lVert f - p \\rVert_{\\infty} = \\inf_{q \\in \\mathcal{P}_n} \\lVert f - q \\rVert_{\\infty}\n",
    "= \\inf_{q \\in \\mathcal{P}_n}  \\sup_{x \\in D} | f(x) - g(x) |\n",
    "$$\n",
    "\n",
    "Chebyshev proved existence and uniqueness of the best approximating polynomial in uniform norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Chebyshev polynomials\n",
    "\n",
    "- $ [a,b] = [-1,1] $ and $ w(x)=(1-x^2)^{(-1/2)} $  \n",
    "- $ T_n(x)=\\cos\\big(n\\cos^{-1}(x)\\big) $  \n",
    "\n",
    "- Recursive formulas:  \n",
    "$$\n",
    "\\begin{align}\n",
    "T_0(x)&=1,\\\\\n",
    "T_1(x)&=x,\\\\\n",
    "T_{n+1}(x)&=2x T_n(x) - T_{n-1}(x)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "- Chebyshev polynomials are mutually orthogonal wrt to the weighting function $w(x)=(1-x^2)^{(-1/2)}$ \n",
    "\n",
    "- If we approximate f(x) by Chebyshev-least squares, we put equal weight on where we want to minimize the squared error. \n",
    "- The leading term in the maximum error of a $n-1$ degree interpolation is $T_n(x)$\n",
    "- If we want to achieve the best set of interpolation nodes that minimizes the maximum error bound for a degree $n-1$ interpolation, the interpolation nodes $x_1,\\dots, x_n$ must be the zeros of $T_n(x)$\n",
    "$$x_k=cos\\left( \\frac{2k-1}{2n}\\pi\\right), \\quad \\quad k=1,\\dots,n$$\n",
    "\n",
    "- Sometime we use the *expanded* chebyshev nodes (although they are not roots of $T_n(x))$\n",
    "$$x_k=\\frac{\\cos\\left(\\frac{2k-1}{2}\\right)\\pi/n}{\\cos\\left(\\frac{\\pi}{2n}\\right)}, \\quad \\quad k=1,\\dots,n$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's compare basis for Chebyshev and Algebraic polynomials  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "# plot nodes\n",
    "x0,z0 =sieve.grid(n=n, a=0, b=1, gridtype='c') # chebyshev nodes are roots of n-degree chebyshev polynomials\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(z0, z0*0)\n",
    "\n",
    "# plot Chebyshev polynomials up to degree n\n",
    "z=np.linspace(-1,1,100).reshape(-1,1)\n",
    "B=sieve.basis_j(z, deg=n, btype='chebyshev') \n",
    "# B=sieve.basis(z, deg=[n], btype=['algpol']) # Try this and increase degree (does the polynomials appears to be orthogonal)\n",
    "plt.plot(z, B[:,:-1], linewidth=1)\n",
    "plt.plot(z, B[:,-1], linewidth=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Are Chebyshev and Algebraic polynomials orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Compute B(x)'B(x)\n",
    "n=10;deg=n-1; \n",
    "sa=sieve(n, deg, a, b, btype='algpol', gridtype='u');    # basis: (ordinary) Algrbraic polynomials\n",
    "sc=sieve(n, deg, a, b, btype='chebyshev', gridtype='c'); # basis: Chebyshev polynomials\n",
    "print('Algebraic polynomials')\n",
    "disp(sa.B.T@sa.B)\n",
    "print('Chebyshev polynmials')\n",
    "disp(sc.B.T@sc.B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### General interval\n",
    "\n",
    "- Not hard to adapt the polynomials for the general interval\n",
    "  $ [a,b] $ through linear change of variable  \n",
    "\n",
    "\n",
    "$$\n",
    "y = 2\\frac{x-a}{b-a}-1\n",
    "$$\n",
    "\n",
    "- Orthogonality holds with weights function with the same change of\n",
    "  variable  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Chebyshev approximation algorithm\n",
    "\n",
    "1. Given $ f(x) $ and $ [a,b] $  \n",
    "1. Compute Chebyshev interpolation nodes on $ [-1,1] $  \n",
    "1. Adjust nodes to $ [a,b] $ by change of variable, $ x_i $  \n",
    "1. Evaluate $ f $ at the nodes, $ f(x_i) $  \n",
    "1. Compute Chebyshev coefficients $ a_i = g\\big(f(x_i)\\big) $  \n",
    "1. Arrive at approximation  \n",
    "\n",
    "\n",
    "$$\n",
    "f(x) = \\sum_{i=0}^n a_i T_i(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Accuracy of Chebyshev interpolation\n",
    "\n",
    "Suppose $ f: [-1,1]\\rightarrow R $ is $ C^k $ function for some\n",
    "$ k\\ge 1 $, and let $ I_n $ be the degree $ n $ polynomial\n",
    "interpolation of $ f $ with nodes at zeros of $ T_{n}(x) $.\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\lVert f - I_n \\rVert_{\\infty} \\le \\left( \\frac{2}{\\pi} \\log(n+1) +1 \\right) \\frac{(n-k)!}{n!}\\left(\\frac{\\pi}{2}\\right)^k \\lVert f^{(k)}\\rVert_{\\infty}\n",
    "$$\n",
    "\n",
    "üìñ Judd (1988) Numerical Methods in Economics\n",
    "\n",
    "- achieves *best polynomial approximation in uniform norm*  \n",
    "- works for smooth functions\n",
    "- easy to compute  \n",
    "- but *does not* approximate $ f'(x) $ well  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# compute factor proportional to ||f(k)|| appearing in error\n",
    "import math\n",
    "k=10\n",
    "for n in range(k,k+5,1):\n",
    "    z=(   (2/math.pi*math.log(n+1)+1)*(math.factorial(n-k)/math.factorial(n)*(math.pi/2)**k) ) /(math.factorial(2*n+1) * math.factorial(2*n)**2)\n",
    "    print('k=', k, 'n=', n,  'z=', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limits to polynomial interpolation/approximation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1 = lambda x: np.minimum(np.maximum(4*(x-0.2),-1),1)   # function to approximate (for a=-1,b=1)\n",
    "#f1= lambda x: np.exp(-x/4)*np.sin(x) + 1/(1+x**2)       # function to interpolate/approximate (smooth on small intervals)\n",
    "f2 = lambda x: np.log(x)                               # function to approximate (only for x>0)\n",
    "deg=10; n=deg+1;    # Try increasing degree and number of nodes\n",
    "btype='chebyshev'; gridtype='c'; # \n",
    "# btype='algpol'; gridtype='u'; # Try algpol\n",
    "s1=sieve(n, deg, a=-2, b=2,   btype=btype, gridtype=gridtype);  \n",
    "s2=sieve(n, deg, a=0.00001, b=10, btype=btype, gridtype=gridtype);  \n",
    "s1.plot1d(f1); plt.show() # basis: Chebyshev polynomials \n",
    "s2.plot1d(f2); plt.show() # basis: (ordinary) Algrbraic polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformation - what if we could approximate a transformation of $f(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deg=10; n=deg+1;    # Try increasing degree and number of nodes\n",
    "f1 = lambda x: np.log(x)  # function to approximate (only for x>0)\n",
    "Œ≤=0.8; V= lambda x: np.log(x)/(1-Œ≤) + np.log(1-Œ≤)/(1-Œ≤) + Œ≤ *np.log(Œ≤)/((1-Œ≤)**2)\n",
    "# f1 = V # TRY Value function for cake eating problem\n",
    "btype='chebyshev'; gridtype='c'; \n",
    "s=sieve(n, deg, a=0.00001, b=1, btype=btype, gridtype=gridtype);  \n",
    "s_tr=sieve(n, deg, a=0.00001, b=10, btype=btype, gridtype=gridtype, transform=lambda x: np.exp(x), inv_transform=lambda x: np.log(np.maximum(x, 1e-20)));  \n",
    "s.plot1d(f1); plt.show() # basis: Chebyshev polynomials \n",
    "s_tr.plot1d(f1, label='Transformed'); plt.show() # basis: (ordinary) Algrbraic polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extrapolation\n",
    "\n",
    "Extrapolation is computing the approximated function outside of the\n",
    "original data interval\n",
    "\n",
    "**Should be avoided in general**\n",
    "\n",
    "- Exact *only* when theoretical properties of the extrapolated function\n",
    "  are known  \n",
    "- Can be used with extreme caution and based on the analysis of the model  \n",
    "- Always try to introduce wider bounds for the grid instead  \n",
    "\n",
    "**NEVER extrapolate high degree polynomials.**: Nodes are like hands that tries to fix a wild snake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "m=5; a=0; b=5; extrapolate=5            # try increasing m (does linear gets worse, does polynmial)               \n",
    "x0 = np.linspace(a,b,m);                 # x0:  grid points where we know f(x)\n",
    "x1 =  np.linspace(a,b+extrapolate,100);            # x1:  extended grid points for extrapolation\n",
    "f= lambda x: np.exp(-x/4)*np.sin(x) + 1/(1+x**2)       # function to interpolate/approximate (smooth on small intervals)\n",
    "fhat = interpolate.interp1d(x0,f(x0), bounds_error=False, fill_value='extrapolate')    # returns the interpolation function\n",
    "plot1d(None, x0, f(x0)) # use the the plotting tool\n",
    "plot1d(f, x1, None, fhat, label='Linear Extrapolation') # use the the plotting tool\n",
    "Œ± = polynomial.polyfit(x0,f(x0),m-1)     # returns polynomial coeficients\n",
    "fhat = lambda x: polynomial.polyval(x,Œ±)\n",
    "plot1d(None, x1, None, fhat, label='Polynomial extrapolation', color='g') # use the the plotting tool\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spline interpolation\n",
    "\n",
    "Spline = curve composed of independent pieces\n",
    "\n",
    "**Definition** A function $ s(x) $ on $ [a,b] $ is a spline of\n",
    "order $ n $ ( = degree $ n-1 $) iff\n",
    "\n",
    "- $ s $ is $ C^{n-2} $ on $ [a,b] $ (has continuous derivatives\n",
    "  up to order $ n-2 $),  \n",
    "- given *knot* points $ a=x_0<x_1<\\dots<x_m=b $, $ s(x) $ is a\n",
    "  polynomial of degree $ n-1 $ on each subinterval\n",
    "  $ [x_i,x_{i+1}] $, $ i=0,\\dots,m-1 $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Cubic splines = spline of order 4\n",
    "\n",
    "- Data set $ \\{(x_i,f(x_i), i=0,\\dots,n\\} $  \n",
    "- Functional form $ s(x) = a_i + b_i x + c_i x^2 + d_i x^3 $ on\n",
    "  $ [x_{i-1},x_i] $ for $ i=1,\\dots,n $  \n",
    "- $ 4n $ unknown coefficients:  \n",
    "- $ 2n $ equations to make sure each segment passes through its interval points +\n",
    "  $ 2(n-1) $ equations to ensure two continuous derivatives at each interior point  \n",
    "- Additional 2 equation for the $ x_0 $ and $ x_n $  \n",
    "  - $ s''(x_0)=s''(x_n)=0 $ (natural spline)  \n",
    "  - $ s'(x_0)=\\frac{s(x_1)-s(x_0)}{x_1-x_0} $,\n",
    "    $ s'(x_n)=\\frac{s(x_n)-s(x_{n-1})}{x_n-x_{n-1}} $\n",
    "    (secant-Hermite)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### B-splines\n",
    "- B-splines play the role of basis functions for the spline function space, hence the name. \n",
    "- Expressions for the polynomial (all of same degree k) pieces can be derived by means of the Cox‚Äìde Boor recursion formula\n",
    "$$ B_{i,0}(x):={\\begin{cases}1&{\\text{if }}t_{i}\\leq x<t_{i+1},\\\\0&{\\text{otherwise}}.\\end{cases}}$$\n",
    "\n",
    "$$B_{i,k}(x):={\\frac {x-t_{i}}{t_{i+k}-t_{i}}}B_{i,k-1}(x)+{\\frac {t_{i+k+1}-x}{t_{i+k+1}-t_{i+1}}}B_{i+1,k-1}(x).$$\n",
    "- That is, $B_{j,0}(x)$ is piecewise constant one or zero indicating which knot span $x$ is in (zero if knot span j is repeated). \n",
    "- The recursion equation is in two parts, where\n",
    "$${\\frac {x-t_{i}}{t_{i+k}-t_{i}}}$$\n",
    "ramps from zero to one as $x$ goes from $t_{i}$ to $t_{i+k}$, and $${\\frac {t_{i+k+1}-x}{t_{i+k+1}-t_{i+1}}}$$ ramps from one to zero as x goes from \n",
    "$t_{i+1}$ to $t_{i+k+1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### B-splines  - basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "k=1                            # polynomial degree (Try 0,1,2,)\n",
    "nknots=10                      # number of internal knots (Try)\n",
    "a=0; b=100;                    # min and max\n",
    "knots=np.linspace(a,b,nknots)  # internal knots\n",
    "x=np.linspace(a,b,1000)        # evaluation point for plotting\n",
    "B=sieve.basis_j(x, deg=k, btype='b-spline', knots=knots) \n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(knots, knots*0)\n",
    "plt.plot(x, B, linewidth=3)\n",
    "plt.title('B-Splines of degree %d based on %d internal knots'% (k,nknots))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### B-splines versus Chebyshev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=-10; b=10; f = lambda x: np.minimum(np.maximum(4*(x-0.2),-1),1)   # \"kinky\" function to approximate (for a=-1,b=1)\n",
    "#a=-1; b=1; f = lambda x: np.exp(-x/4)*np.sin(x) + 1/(1+x**2)      # smooth function \n",
    "n=20; deg_spl=1; # Try chnaging degree of spline, addining more points and change interval.  \n",
    "sb=sieve(n, deg_spl, a, b, btype='b-spline', gridtype='u', nknots=None);      sb.plot1d(f); plt.show() # basis: B-spline\n",
    "sc=sieve(n, n-1, a, b, btype='chebyshev', gridtype='c');   sc.plot1d(f); plt.show() # basis: Chebyshev polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multidimensional interpolation/approximation\n",
    "\n",
    "- there are multidimensional generalization to all methods based on sieves  \n",
    "- We consider a tensor product basis: curse of dimensionality in the number of interpolation points when number of dimensions increase  \n",
    "\n",
    "**Generally much harder!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We can do it: Let's try a tensor product basis of Chebyshev polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1 = lambda x: np.sin(np.sum(x, axis=1)).reshape(-1,1)           # smooth function with some nonlinear interaction\n",
    "f1 = lambda x: np.sum(np.sin(2*x), axis=1).reshape(-1,1)         # additively seperable smooth function\n",
    "#f1 = lambda x: np.log(np.sum(np.abs(x), axis=1)).reshape(-1,1)  # nasty fuction\n",
    "s1=sieve(n=[11, 11], a=-1, b=2, btype='chebyshev', gridtype='c') # sieve setup\n",
    "fx=f1(s1.x)        # y-data at nodes s1.x\n",
    "Œ± = s1.fit(fx)     # sieve coeficients             \n",
    "\n",
    "neval=[50,50]      # evaluation of function and interpolant on finer grid  \n",
    "x, z=sieve.grid(n=neval, a=s1.a, b=s1.b, gridtype='u')\n",
    "fhat=s1.eval(x, Œ±)\n",
    "\n",
    "# plotting\n",
    "fig=plot2d(x,f1(x), neval, i=1)\n",
    "fig=plot2d(x,fhat, neval, fig=fig, i=2, label='Interpolation')\n",
    "fig=plot2d(x,fhat-f1(x), neval, fig=fig, i=3, label='Approximation error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approximation in $R^d$\n",
    "Recall our sieve approximation in the 1-dimensional case\n",
    "$$f(x) \\approx s(x,\\alpha)= \\sum_{j=0}^{n} \\alpha_j B_j(x) $$\n",
    "where \n",
    "- $B_j(x)=B_{j,k}(x)$ for the B-Spline of degree $k$ for interval $j$ (sorry for using same notation for B splines and Basis functions)\n",
    "- $B_j(x)=B_{j,0}(x)=\\mathbb{1}(x_j\\le x < x_{j+1}) $ the step-function (B-spline of degree 0 for interval j)\n",
    "- $B_j(x)=x^j$ for a simple algebraic polynomial of degree $j$ \n",
    "- $B_j(x)=T_j(x)$ for Chebyshev polynomials of degree $j$\n",
    "\n",
    "This formula can be directly generalized to d dimensions:\n",
    "$$f(x_1,\\dots,x_d) \\approx s(x_1,\\dots,x_d,\\alpha)=  \\sum_{i_1=0}^{n_1} \\dots \\sum_{i_d=0}^{n_d}  \\alpha_{i_1\\dots \n",
    "i_d} \\prod_{k=1}^d B_{i_k}(x_{k})$$\n",
    "For d=2 we have\n",
    "$$f(x_1,x_2) \\approx s(x_1,x_2,\\alpha)=  \\sum_{i_1=0}^{n_1} \\sum_{i_2=0}^{n_2}  \\alpha_{i_1,\n",
    "i_2}  B_{i_1}(x_{1}) B_{i_2}(x_{2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Looks nasty, but is quite easy with matrix notation\n",
    "$$f(x_1,\\dots,x_d)=\\mathbf{B(x)}\\alpha$$ \n",
    "where \n",
    "- $\\mathbf{B(x)}$ is the matrix with as many rows as we have grid-points and as many columns as we cam make combinations of basis functions across the $d$ dimensions d with $n_d+1$ basis functions in each dimension. \n",
    "- $\\mathbf{B(x)}$ has $\\prod_{k=1}^d (n_d+1)$ columns.\n",
    "- $\\alpha$ is a vector of coefficients with $\\prod_{k=1}^d (n_d+1)$ rows\n",
    "- To identify all coefficients we need at least $\\prod_{k=1}^d (n_d+1)$ DISTRICT points on our grid. We can this as the so called Cartesian grid that gives all combinations of gridpoints used in dimensions $k=1,\\dots,d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### .... and even easier in Python. Let's first do the Cartesian grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cartesian(x):\n",
    "    d=len(x)\n",
    "    return np.array(np.meshgrid(*x)).T.reshape(-1,d)\n",
    "\n",
    "x1=np.linspace(1,2,2); x2=np.linspace(3,5,3);  x=[x1, x2]; \n",
    "X=cartesian(x)\n",
    "print('x1=', x1)\n",
    "print('x2=', x2)\n",
    "print('X', X)\n",
    "disp(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### .... and and now the d fold tensor product basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tensor(b): \n",
    "    '''k-fold tensor product list of matrices b=[b[0],b[1],...,b[k-1]]'''\n",
    "    T=b[0]   # Initialize Tensor product basis with first element in b \n",
    "    for j in range(len(b)-1): # loop over remainng dimensions in b\n",
    "        T=(T[:,:,None]*b[j+1][:,None,:]).reshape(T.shape[0],-1)  # use boradcasting\n",
    "    return T\n",
    "\n",
    "B1=sieve.basis_j(X[:,0], deg=2, btype='algpol')\n",
    "B2=sieve.basis_j(X[:,1], deg=2, btype='algpol')\n",
    "\n",
    "print('B1'); disp(B1)\n",
    "print('B2'); disp(B2)\n",
    "\n",
    "T=tensor([B1,B2])\n",
    "print('T', T.shape); disp(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Before we look at coefficients let's consider our 2-d Chebyshev approximation from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# f1 = lambda x: np.sin(np.sum(x, axis=1)).reshape(-1,1)         # smooth function with some nonlinear interaction (TRY and inspect coefficnets on next slide)\n",
    "f1 = lambda x: np.sum(np.sin(2*x), axis=1).reshape(-1,1)         # additively seperable smooth function (TRY and inspect coefficnets on next slide)\n",
    "#f1 = lambda x: np.log(np.sum(np.abs(x), axis=1)).reshape(-1,1)  # nasty fuction\n",
    "s1=sieve(n=[11, 11], a=-1, b=2, btype='chebyshev', gridtype='c') # sieve setup\n",
    "fx=f1(s1.x)        # y-data at nodes s1.x\n",
    "Œ± = s1.fit(fx)     # sieve coeficients             \n",
    "\n",
    "neval=[50,50]      # evaluation of function and interpolant on finer grid  \n",
    "x, z=sieve.grid(n=neval, a=s1.a, b=s1.b, gridtype='u')\n",
    "fhat=s1.eval(x, Œ±)\n",
    "\n",
    "# plotting\n",
    "fig=plot2d(x,f1(x), neval, i=1)\n",
    "fig=plot2d(x,fhat, neval, fig=fig, i=2, label='Interpolation')\n",
    "fig=plot2d(x,fhat-f1(x), neval, fig=fig, i=3, label='Approximation error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How does the coefficients look like?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try to inspect coefficients when approximating function with dependence x1 and x2 \n",
    "# (use one of the alternative functions just above)\n",
    "print('Transposed coefficients')\n",
    "disp(Œ±.reshape(s1.deg[0]+1,s1.deg[1]+1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's try a tensor product basis of B-splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1 = lambda x: np.sin(np.sum(x, axis=1)).reshape(-1,1)           # smooth function with some nonlinear interaction\n",
    "f1 = lambda x: np.sum(np.sin(2*x), axis=1).reshape(-1,1)         # additively seperable smooth function\n",
    "#f1 = lambda x: np.log(np.sum(np.abs(x), axis=1)).reshape(-1,1)  # nasty fuction\n",
    "s1=sieve(n=[11, 11], deg=[3], a=-1, b=2, btype=['b-spline'], gridtype=['u']) # sieve setup - try different defgrees\n",
    "#s1=sieve(n=[11, 11], deg=[3,10], a=-1, b=2, btype=['b-spline','chebyshev'], gridtype=['u','c']) # sieve setup - try different defgrees\n",
    "fx=f1(s1.x)        # y-data at nodes s1.x\n",
    "Œ± = s1.fit(fx)     # sieve coeficients             \n",
    "\n",
    "neval=[50,50]      # evaluation of function and interpolant on finer grid  \n",
    "x, z=sieve.grid(n=neval, a=s1.a, b=s1.b, gridtype='u')\n",
    "fhat=s1.eval(x, Œ±)\n",
    "\n",
    "# plotting\n",
    "fig=plot2d(x,f1(x), neval, i=1)\n",
    "fig=plot2d(x,fhat, neval, fig=fig, i=2, label='Interpolation')\n",
    "fig=plot2d(x,fhat-f1(x), neval, fig=fig, i=3, label='Approximation error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Coefficients for Spline approximation is dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Transposed coefficients')\n",
    "disp(Œ±.reshape(s1.nknots[0]+2,s1.nknots[1]+2)) \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Curse of dimensionality\n",
    "- It may be easy to program, but the tensor product basis i subject to **CURSE OF DIMENSIONALITY**. \n",
    "- The number of basis functions, corresponding coefficients and required nodes are all exponentially increasing in $d$\n",
    "- Sparse Smolyak grids and adaptive sparse grids  \n",
    "- Do we need the regular Cartesian grid\n",
    "- Perhaps randomization can break the curse of dimensionality\n",
    "- Irregular grids require computationally expensive triangulation in the general case\n",
    "- Good application for machine learning!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Further learning resources\n",
    "\n",
    "- [https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html](https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html)  \n",
    "- [https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html)  \n",
    "- M.H. Mudde‚Äôs thesis on Chebyshev approximation [http://fse.studenttheses.ub.rug.nl/15406/1/Marieke_Mudde_2017_EC.pdf](http://fse.studenttheses.ub.rug.nl/15406/1/Marieke_Mudde_2017_EC.pdf)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some calls and illustrations using build in Python routines in 1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2008) # fix random number sequences\n",
    "x  = np.sort(np.random.uniform(-5,10,12)) # sorted random numbers on [-5,10]\n",
    "xr = np.linspace(-5,10,12) # regular grid on [-5,10]\n",
    "\n",
    "func=lambda x: np.exp(-x/4)*np.sin(x) + 1/(1+x**2) # function to interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot1(ifunc,fdata=(x,func(x)),f=func,color='b',label='',extrapolation=False):\n",
    "    '''helper function to make plots'''\n",
    "    xd = np.linspace(-5,10,1000) # for making continuous lines\n",
    "    plt.figure(num=1, figsize=(10,8))\n",
    "    plt.scatter(fdata[0],fdata[1],color='r') # interpolation data\n",
    "    plt.plot(xd,f(xd),color='grey') # true function\n",
    "    if extrapolation:\n",
    "        xdi = xd\n",
    "    else:\n",
    "        # restriction for interpolation only\n",
    "        xdi=xd[np.logical_and(xd>=fdata[0][0],xd<=fdata[0][-1])]\n",
    "    if ifunc:\n",
    "        plt.plot(xdi,ifunc(xdi),color=color,label=label)\n",
    "        if label:\n",
    "            plt.legend()\n",
    "    elif label:\n",
    "        plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate # Interpolation routines\n",
    "fhat = interpolate.interp1d(x,f(x)) # returns the interpolation function\n",
    "plot1d(f, x, f(x), fhat,label='interp1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "help(interpolate.interp1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fhat = interpolate.interp1d(x,f(x),kind='linear')\n",
    "plot1d(f, x, f(x), fhat,label='Linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot1d(f, x, f(x))\n",
    "for knd, clr in ('previous','m'),('next','b'),('nearest','g'):\n",
    "    fhat = interpolate.interp1d(x,func(x),kind=knd)\n",
    "    plot1d(x0=x, fhat=fhat, label=knd,color=clr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for knd, clr in ('slinear','m'),('quadratic','b'),('cubic','g'):\n",
    "    fi = interpolate.interp1d(x,f(x),kind=knd)\n",
    "    plot1(fi,color=clr,label=knd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Approximation errors\n",
    "x = np.sort(np.random.uniform(-5,10,11))  # generate new data\n",
    "for knd, clr in ('slinear','m'),('quadratic','b'),('cubic','g'):\n",
    "    fi = interpolate.interp1d(x,func(x),kind=knd,bounds_error=False)\n",
    "    xd = np.linspace(-5,10,1000)\n",
    "    erd=np.abs(func(xd)-fi(xd))\n",
    "    plt.plot(xd,erd,color=clr)\n",
    "    print('Max error with  %s splines is %1.5e'%(knd,np.nanmax(erd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Approximation errors for regular grid\n",
    "for knd, clr in ('slinear','m'),('quadratic','b'),('cubic','g'):\n",
    "    fi = interpolate.interp1d(xr,func(xr),kind=knd,bounds_error=False)\n",
    "    xd = np.linspace(-5,10,1000)\n",
    "    erd=np.abs(func(xd)-fi(xd))\n",
    "    plt.plot(xd,erd,color=clr)\n",
    "    print('Max error with  %s splines is %1.5e'%(knd,np.nanmax(erd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Accuracy of the interpolation\n",
    "\n",
    "How to reduce approximation errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Number of nodes (more is better)  \n",
    "- Location of nodes (regular is better)  \n",
    "- Interpolation type (match function of interest)  \n",
    "\n",
    "\n",
    "*In economic models we usually can control all of these*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.polynomial import polynomial\n",
    "degree = len(x)-1 # passing through all dots\n",
    "p = polynomial.polyfit(x,func(x),degree)\n",
    "fi = lambda x: polynomial.polyval(x,p)\n",
    "plot1(fi,label='Polynomial of degree %d'%degree,extrapolation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# now with regular grid\n",
    "degree = len(xr)-1 # passing through all dots\n",
    "p = polynomial.polyfit(xr,func(xr),degree)\n",
    "print(p.shape)\n",
    "fi = lambda x: polynomial.polyval(x,p)\n",
    "plot1(fi,fdata=(xr,func(xr)),label='Polynomial of degree %d'%degree,extrapolation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# how number of points affect the approximation (with degree=n-1)\n",
    "for n, clr in (5,'m'),(10,'b'),(15,'g'),(25,'r'):\n",
    "    x2 = np.linspace(-5,10,n)\n",
    "    p = polynomial.polyfit(x2,func(x2),n-1)\n",
    "    fi = lambda x: polynomial.polyval(x,p)\n",
    "    plot1(fi,fdata=(x2,func(x2)),label='%d points'%n,color=clr,extrapolation=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# how locations of points affect the approximation (with degree=n-1)\n",
    "np.random.seed(2025)\n",
    "n=8\n",
    "for clr in 'b','g','c':\n",
    "    x2 = np.linspace(-4,9,n) + np.random.uniform(-1,1,n) # perturb points a little\n",
    "    p = polynomial.polyfit(x2,func(x2),n-1)\n",
    "    fi = lambda x: polynomial.polyval(x,p)\n",
    "    plot1(fi,fdata=(x2,func(x2)),label='%d points'%n,color=clr,extrapolation=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# how degree of the polynomial affects the approximation\n",
    "for degree, clr in (7,'b'),(9,'g'),(11,'m'):\n",
    "    p=polynomial.polyfit(xr,func(xr),degree)\n",
    "    fi=lambda x: polynomial.polyval(x,p)\n",
    "    plot1(fi,fdata=(xr,func(xr)),label='Polynomial of degree %d'%degree,color=clr,extrapolation=True)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "date": 1612589586.079556,
  "download_nb": false,
  "filename": "01_dp_intro.rst",
  "filename_with_path": "01_dp_intro",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "title": "Dynamic Programming and Structural Econometrics #1"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
